\chapter{Discussion}

\paragraph{}
This study showed that detecting traffic sign on low end devices mobile is now possible. However, there is still a wide range of possible improvement and experimentation to explore, this research also open the way to a wide range of application ranging from infrastructure assessment to real time driver assistance and autonomous driving.

\paragraph{}
The scope of this study was limited to the detection of US warning signs. During this study we trained and tested our model on a wide range of cases, with data collected from Georgia and other neighboring states. More testing would allow to get a better assessment of the performance of the model. One example of case the model never encountered is snow. While show is not impossible in that region of the United States, it is fairly uncommon and does not appear on our data. So doing additional testing would allow a better assessment of the quality of the model.

The model was designed with multiple class detection in mind, but this functionality was never tested because out of the scope of this work. Using multiple class detection could, however, improve the detection by improving the feature extracted by the backbone network. On an application point of view, this will also allow to have a larger impact. We advise in this case to define different anchors for each classes, while trying to stay at similar scales.

This study was also focused on the creation of an architecture that is able to run on mobile devise. If we have some demo and test demonstrating these capabilities, they are packaged for production. A future task could be to implement a proper pipeline in mobile device to run the detection, as well as other processing step, such as classification, directly on the device. This would allow a production usage of the method developed here.

We tested and tuned our model to run on a Samsung S6 (SM-G920T), this device is not completely outdated, but is still far from the performance of newer smartphone. This was done on purpose, you do not want the model to only run on recent flagship devices, but also to run a nearly any smartphone available on the market. However, taking advantage of the newer devices should allow producing deeper and better models. This area is not explored here and is left open to latter research.

A classical approach to speed up inference on mobile device is to use model quantification. We described this approach in Chapter \ref{subsec:optMobileDevice}. During our experiment we used weights quantification, which speed up the inference my a small amount, but is mainly designed to reduce the size of the weights to transfers to the mobile device. We planned to use full model quantification, that have shown to give great results on mobile device, giving large speed-up while reducing the accuracy by only a small amount. Unfortunately, due to a bug in the current TensorFlow version (2.0.0) we were not able to explore this solution. Using this method should bring some more speed up and provide even better performances. Latter research should be able to use that to provide a large improvement over the current results.

Lot of previous study \cite{sandler2018mobilenetv2, howard2019mobilenetv3} showed the benefit of using architecture such as Inverted residual bottleneck on mobile device. During this study we were not able to reproduce such benefit. During our experiment the inverted residual bottleneck were at best as accurate as a residual convolution but slower on a mobile device. The true benefit of this kind of block may only come after a complete quantification of the network, which we were not able to perform as stated previously. In \cite{howard2019mobilenetv3} the authors proposed to add an attention mechanism improving the results a bit more, as well as the switch activation function on last layers. We did not try to implement those improvements because of the results we get on the original version, but ultimately this structure is supposed to improve the performance of the model and is so a good starting point for latter research.

As we discussed previously, we purposely reduced the localization and size accuracy of this model in order to make the task easier. However, it is still unclear how much speed up we were able to get from this reduced accuracy, testing similar architecture with added localization and size prediction may help to quantify the effect of these choices, and could improve the mAP results.

To improve accuracy, we also propose a way to artificially generate data for training. If we showed that this data helped a lot to improve the final results, we believe that a lot of things can be added to this procedure to make it more diverse and cover slightly more realistic case. Some of this improvement could be to add shadow like shape, add motion blur or simply use gradient in the shape instead of flat colors.

\paragraph{}
This work brings large improvement on the traffic sign detection on mobile device, but is only the starting point of this approach. If generic object detection is a problem that is globally solved, doing it with low computational impact is still an open problem. Here we fine-tuned an architecture for this particular task, but our research space did not cover all the possibilities which leave open questions for future research.


